# ğŸš€ Pipeline ETL â€“ Servidores PÃºblicos

Projeto prÃ¡tico de Engenharia de Dados.

---

## ğŸ¯ VisÃ£o Geral

Este projeto realiza um pipeline completo de ETL (**ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga**) com as seguintes etapas:

1. **ExtraÃ§Ã£o:** coleta dados do Portal da TransparÃªncia de Alagoas (API JSON).
2. **Carga:** salva os dados brutos em banco PostgreSQL.
3. **TransformaÃ§Ã£o:** realiza limpeza e padronizaÃ§Ã£o usando DBT.
4. **OrquestraÃ§Ã£o:** automatiza e gerencia o pipeline usando Prefect Cloud.

---

## ğŸ§° Tecnologias Utilizadas

| Camada        | Ferramenta                 | DescriÃ§Ã£o                            |
| ------------- | -------------------------- | ------------------------------------ |
| OrquestraÃ§Ã£o  | **Prefect Cloud (v3)**     | AutomaÃ§Ã£o, monitoramento e deploy    |
| TransformaÃ§Ã£o | **DBT**                    | TransformaÃ§Ã£o SQL modular e testÃ¡vel |
| Armazenamento | **PostgreSQL**             | Armazena dados brutos e tratados     |
| ExtraÃ§Ã£o      | **Python 3.11 + Requests** | Consumo de API JSON                  |
| Tratamento    | **Pandas**                 | ManipulaÃ§Ã£o e prÃ©-processamento      |
| ConexÃ£o BD    | **SQLAlchemy**             | ComunicaÃ§Ã£o Python com PostgreSQL    |
| ConfiguraÃ§Ã£o  | **python-dotenv**          | Gerenciamento de variÃ¡veis sensÃ­veis |

---

## ğŸ“‚ Estrutura do Projeto

```
engenharia_dados/
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ scrapping.py           # ExtraÃ§Ã£o e carga inicial
â”‚   â””â”€â”€ criar_banco.py         # CriaÃ§Ã£o do banco e tabelas
â”œâ”€â”€ flows/
â”‚   â””â”€â”€ flow_etl.py            # DefiniÃ§Ã£o do fluxo Prefect
â”œâ”€â”€ dbt_project/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ transformacoes/
â”‚   â”‚       â”œâ”€â”€ servidores.sql
â”‚   â”‚       â””â”€â”€ servidores_tratados.sql
â”‚   â””â”€â”€ dbt_project.yml
â”œâ”€â”€ prefect.yaml               # ConfiguraÃ§Ã£o Prefect Cloud
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clone o repositÃ³rio e configure o ambiente

```bash
git clone https://github.com/vitfreire/Engenharia_dados.git
cd <repo>

# Criar ambiente virtual
python -m venv .venv

# Ativar ambiente
# Windows
.venv\Scripts\activate
# Linux/macOS
source .venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. ConfiguraÃ§Ã£o das variÃ¡veis de ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
DB_USER=<usuario>
DB_PASSWORD=<senha>
DB_HOST=localhost
DB_PORT=5432
DB_NAME=transparencia

API_ANO=2023
API_MES=7
API_LIMIT=200
API_OFFSET=0
```

Essas variÃ¡veis serÃ£o carregadas automaticamente pelo script com `load_dotenv()`.

### 3. ConfiguraÃ§Ã£o DBT (fora do repositÃ³rio)

Crie ou edite o arquivo `~/.dbt/profiles.yml`:

```yaml
transparencia:
  target: dev
  outputs:
    dev:
      type: postgres
      host: "{{ env_var('DB_HOST') }}"
      user: "{{ env_var('DB_USER') }}"
      password: "{{ env_var('DB_PASSWORD') }}"
      port: 5432
      dbname: "{{ env_var('DB_NAME') }}"
      schema: public
      threads: 1
```

---

## ğŸƒâ€â™€ï¸ ExecuÃ§Ã£o Local

Execute os scripts na sequÃªncia abaixo:

```bash
python etl/criar_banco.py          # Cria banco e tabelas
python flows/flow_etl.py           # Executa o pipeline completo
```

---

## â˜ï¸ Deploy com Prefect Cloud

### 1. AutenticaÃ§Ã£o

```bash
prefect cloud login
```

### 2. CriaÃ§Ã£o do Deployment

```bash
prefect deploy
```

### 3. ExecuÃ§Ã£o via interface web

No Prefect Cloud:

```
Flows â†’ pipeline_etl â†’ Deployments â†’ pipeline_servidores_deploy â†’ Run
```


## ğŸ“Œ Autoria

**VitÃ³ria Freire**
Analista de Sistemas
[LinkedIn](https://www.linkedin.com/in/vitoriafreiredev)

---




